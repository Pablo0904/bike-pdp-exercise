---
title: "XAI3"
author: "CB_EF_PT"
date: "2025-05-02"
output:
  html_document: default
  word_document: default
---

##Exercise 1
#Partial Dependence Plot

```{r}
# Load required libraries

library(randomForest)
library(pdp)
library(ggplot2)

# Load the dataset
data <- read.csv("day.csv")

# Preview the dataset
head(data)
```


```{r}
# Create a new feature: days since Jan 1, 2011
data$days_since_2011 <- 365 * data$yr + data$mnth * 30 + data$weekday

# Fit a Random Forest model to predict bike rentals (cnt)
set.seed(123)
rf_model <- randomForest(cnt ~ . - instant - dteday - casual - registered, 
                         data = data, 
                         ntree = 500, 
                         importance = TRUE)

# View feature importance
print(importance(rf_model))
```


```{r}
# Partial Dependence Plot for temperature
pdp_temp <- partial(rf_model, pred.var = "temp", grid.resolution = 20)
plot(pdp_temp, 
     main = "Partial Dependence Plot - Temperature", 
     xlab = "Normalized Temperature", 
     ylab = "Predicted Bike Rentals")

# Partial Dependence Plot for humidity
pdp_hum <- partial(rf_model, pred.var = "hum", grid.resolution = 20)
plot(pdp_hum, 
     main = "Partial Dependence Plot - Humidity", 
     xlab = "Humidity", 
     ylab = "Predicted Bike Rentals")

# Partial Dependence Plot for wind speed
pdp_wind <- partial(rf_model, pred.var = "windspeed", grid.resolution = 20)
plot(pdp_wind, 
     main = "Partial Dependence Plot - Wind Speed", 
     xlab = "Wind Speed", 
     ylab = "Predicted Bike Rentals")

# Partial Dependence Plot for days since 2011
pdp_days <- partial(rf_model, pred.var = "days_since_2011", grid.resolution = 20)
plot(pdp_days, 
     main = "Partial Dependence Plot - Days Since 2011", 
     xlab = "Days Since 2011", 
     ylab = "Predicted Bike Rentals")

```


**Days Since 2011 (days_since_2011)**
The partial dependence plot for days_since_2011 shows an upward trend in the predicted number of bike rentals as time progresses since the beginning of the dataset (starting in 2011). This suggests that the model has learned that rentals tend to increase steadily over time. Several external factors might explain this growth, such as urban expansion, improvements in cycling infrastructure, public campaigns promoting bike use, or behavioral shifts among users. The increase is not strictly linear but clearly upward, indicating a consistently positive influence of this variable on rental predictions.

**Temperature (temp)**
Temperature has a clearly positive effect on the predicted bike rental counts. The PDP shows that as temperature rises, the model predicts a higher number of rentals. This matches real-world behavior: people are more likely to bike when the weather is pleasant. However, this increase is not linear; the effect becomes stronger at moderate temperatures and then stabilizes or slightly declines at very high temperatures, likely because extreme heat may discourage cycling. Overall, the model has captured a nonlinear but strongly positive relationship between temperature and bike rentals.

**Humidity (hum)**
In the case of humidity, the effect on rental predictions is negative. The PDP indicates that as humidity increases, the number of predicted bike rentals decreases. This can be explained by the discomfort of riding in humid conditions, which are often associated with rain or poor weather—conditions that typically discourage bike use. While the negative effect is not as dramatic as with other variables, it is consistent. The model reduces its rental predictions on more humid days, reflecting a moderate negative influence of this variable.

**Wind Speed (windspeed)**
Wind speed also shows a negative relationship with bike rentals. The PDP reveals that as wind speed increases, the predicted rental counts decline. This makes practical sense, as strong winds can make cycling physically more difficult, especially for longer trips or for less experienced riders. Although the downward slope in the PDP is not extremely steep, it does show a steady decline, indicating that the model associates windier conditions with lower demand.

**Conclusion**
Together, these four variables have different effects on the model’s predictions. Temperature and days since 2011 show a clearly positive influence, reflecting the expected pattern of increasing bike usage over time and during comfortable weather. On the other hand, humidity and wind speed act as deterrents, lowering the model’s rental predictions when their values are high. These results demonstrate that the Random Forest model has successfully learned complex, nonlinear relationships that align well with real-world human behavior regarding bike usage.

# Exercise 2

```{r}
# Cargar librerías necesarias
library(randomForest)
library(pdp)
library(ggplot2)
library(gridExtra)  # Para combinar plots si lo deseas

# Crear una muestra aleatoria para evitar problemas de rendimiento
set.seed(123)
sample_data <- data[sample(nrow(data), 500), ]  # Puedes ajustar el tamaño

# Ajustar el modelo Random Forest sobre la muestra
rf_model_sample <- randomForest(cnt ~ . - instant - dteday - casual - registered,
                                data = sample_data,
                                ntree = 500,
                                importance = TRUE)

# Calcular la dependencia parcial bidimensional
pdp_2d <- partial(rf_model_sample,
                  pred.var = c("temp", "hum"),
                  grid.resolution = 20,
                  progress = "text")

# Convertir a data frame para ggplot
pdp_df <- as.data.frame(pdp_2d)

# Graficar con geom_tile
ggplot(pdp_df, aes(x = temp, y = hum, fill = yhat)) +
  geom_tile(width = 0.02, height = 0.02) +
  scale_fill_viridis_c(option = "C") +
  labs(
    title = "2D Partial Dependence Plot",
    x = "Normalized Temperature",
    y = "Humidity",
    fill = "Predicted\nBike Rentals"
  ) +
  theme_minimal()

```

```{r}
library(ggplot2)
library(patchwork)

# Densidad temperatura
temp_density <- ggplot(sample_data, aes(x = temp)) +
  geom_density(fill = "lightblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Density of Normalized Temperature")

# Densidad humedad
hum_density <- ggplot(sample_data, aes(x = hum)) +
  geom_density(fill = "lightgreen", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Density of Humidity")

# Mostrar ambos gráficos
temp_density / hum_density

```
*Analysis of PDP*

The 2D Partial Dependence Plot (PDP) illustrates the joint effect of normalized temperature (temp) and humidity (hum) on the predicted number of bike rentals.

- Temperature effect:

The model clearly predicts higher bike rental counts as temperature increases. This is visually represented by the shift from purple (lower predictions) to yellow (higher predictions) along the x-axis. Warmer days are more favorable for biking.

- Humidity effect:

Humidity has a negative correlation with predicted rentals. As humidity increases (y-axis), the expected bike rentals tend to decrease slightly, especially under moderate temperatures.

- Interaction between features:

The most favorable conditions for bike rentals are high temperatures with low humidity, located in the bottom-right corner of the plot. Conversely, low temperatures and high humidity correspond to the lowest rental predictions, in the top-left corner.

- Conclusion:

The Random Forest model has learned a realistic dependency: people are more likely to rent bikes when it's warm and dry, which aligns with practical human behavior.

*Input feature distributions*

- Temperature Distribution:

The normalized temperature shows a bimodal pattern, with two peaks around values 0.35 and 0.7. This suggests that the dataset contains a mix of cool and warm days, but very few extreme cold or hot days.

- Humidity Distribution:

Humidity is skewed to the left, with most values concentrated between 0.4 and 0.7. Extremely dry or very humid days are rare in the dataset.

- Conclusion:

The regions with the highest prediction values in the PDP also correspond to densely populated regions of the data. This means that the model is learning from frequent, meaningful patterns, rather than extrapolating from rare conditions.

## Exercise 3

```{r}
# Load required libraries
library(dplyr)

# Load the dataset
data <- read.csv("kc_house_data.csv")

# Display the first few rows
head(data)
```

```{r}
# Select only the relevant features
data_subset <- data %>%
  select(price, bedrooms, bathrooms, sqft_living, sqft_lot, floors, yr_built)

# Remove any rows with missing values
data_subset <- na.omit(data_subset)

# Create a random sample (to reduce computational load)
set.seed(123)
sample_data <- data_subset[sample(nrow(data_subset), 2000), ]
```

```{r}
# Fit the Random Forest model
rf_model <- randomForest(price ~ bedrooms + bathrooms + sqft_living + sqft_lot + floors + yr_built,
                         data = sample_data,
                         ntree = 500,
                         importance = TRUE)

# Optional: View variable importance
print(importance(rf_model))
```

```{r}
# Function to plot PDP with ggplot2
plot_pdp <- function(model, variable, label_x) {
  pd <- partial(model, pred.var = variable, grid.resolution = 20)
  pd_df <- as.data.frame(pd)
  
  ggplot(pd_df, aes_string(x = variable, y = "yhat")) +
    geom_line(color = "black", size = 1) +                # Line connecting points
    geom_point(color = "black", size = 2) +               # Black points (no border)
    theme_minimal() +
    labs(title = paste("Partial Dependence Plot -", variable),
         x = label_x,
         y = "Predicted Price") +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.title = element_text(size = 12),
      axis.text = element_text(size = 10)
    )
}

# Plot PDPs for selected variables
plot_pdp(rf_model, "bedrooms", "Number of Bedrooms")
plot_pdp(rf_model, "bathrooms", "Number of Bathrooms")
plot_pdp(rf_model, "sqft_living", "Square Feet Living Area")
plot_pdp(rf_model, "floors", "Number of Floors")
```
## Overview and Methodology

Understanding what drives the price of a house is crucial for real estate strategy, both from a business and a client-facing perspective. Using a Random Forest model trained on a representative sample from the kc_house_data.csv dataset, we applied Partial Dependence Plots (PDP) to interpret the global behavior of the model regarding four essential features: bedrooms, bathrooms, sqft_living, and floors. The aim is not only to understand how each variable influences price individually but also to gain actionable insights grounded in the behavior of the model itself.

## Impact of sqft_living: Usable Space Drives Value

The feature that clearly stood out was sqft_living. The relationship here is direct and intuitive: as the living area in square feet increases, the predicted price of the house grows almost exponentially. This behavior is reflected both in the steep slope of the PDP and in the model’s internal importance metrics, where sqft_living shows the highest increase in mean squared error (%IncMSE > 50%). The price curve rises continuously, confirming that this feature holds the greatest predictive power. From a business standpoint, this suggests that highlighting the spaciousness of a property—and even modest extensions—can significantly impact perceived value. The interpretability of this plot is especially strong due to its monotonicity, a desirable property discussed in interpretability theory that eases human understanding.

## Impact of bathrooms: A Marker of Comfort and Luxury

In contrast, bathrooms also exhibits a generally increasing trend, though with more complexity. For homes with 1 to 4 bathrooms, the effect on price is steady but moderate. However, after 4 bathrooms, the predicted price begins to rise more sharply. This indicates a non-linear effect: having additional bathrooms begins to act as a luxury signal rather than just a functional feature. This reinforces the idea of interaction effects mentioned in the interpretability materials—specifically, how the impact of a variable may change depending on the value range. bathrooms is ranked second in importance, suggesting that high-end buyers are willing to pay a premium for comfort and privacy that comes with additional full bathrooms.

## Impact of floors: Architectural Layout and Price Steps

The variable floors showed an interesting stepped pattern. The price increases in blocks—most notably from one to two floors and again from two to three—then plateaus beyond that. This suggests that the architectural type (e.g., single-floor vs. duplex vs. triplex) might serve as a proxy for perceived luxury or space distribution, rather than contributing value in a continuous way. While it’s not as influential as other features, the effect is consistent enough to consider it during marketing or design decisions. The plot’s clear stair-step structure reflects the categorical nature of the variable and aligns with the model’s internal logic.

## Impact of bedrooms: A Misleading Indicator of Value

Bedrooms, surprisingly, turned out to be the least informative feature of the four. The PDP shows a non-monotonic and somewhat erratic influence on predicted price. In particular, properties with 4 bedrooms seemed to correlate with a slight dip in predicted price compared to 3 or 5-bedroom homes. This counterintuitive effect might arise from confounding factors not captured directly in the model—for example, homes with many bedrooms but smaller living areas might signal outdated layouts or lack of renovation. This is a good illustration of what the course material refers to as the limits of observational interpretation: without considering other latent variables or interactions, the raw effect can be misleading. In terms of strategic takeaway, this tells us that simply increasing the number of bedrooms does not guarantee added value; instead, emphasis should be placed on space quality and design.

## Model Interpretability and Practical Relevance

By employing PDPs, which average predictions across all observations, we ensure a global interpretability of the model, giving stakeholders confidence in understanding how these variables drive price regardless of the specific case. This method offers a balance between fidelity and clarity, capturing meaningful relationships while remaining accessible to non-technical decision-makers.

Their main advantage lies in their interpretability and intuitive visualization, making complex model behavior more accessible. However, PDPs assume feature independence and may be misleading in regions with low data density or high feature correlation. For instance, the erratic behavior of bedrooms could be due to hidden interactions not captured in the plot. In the future, combining PDPs with Individual Conditional Expectation (ICE) plots or analyzing interaction effects using H-statistics could provide deeper and more accurate insights.

